{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eede1110-215c-45a6-8c76-f82dd1155d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/administrator/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/administrator/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/administrator/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>High risk problems are address in the prototyp...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>high risk problem address prototyp program mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>To simulate portions of the desired final prod...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>simul portion desir final product quick easi p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1</td>\n",
       "      <td>A prototype program simulates the behaviors of...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>prototyp program simul behavior portion desir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1</td>\n",
       "      <td>Defined in the Specification phase a prototype...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>defin specif phase prototyp stimul behavior po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1</td>\n",
       "      <td>It is used to let the users have a first idea ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>use let user first idea complet program allow ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                             answer  score  correct  \\\n",
       "0  1.1  High risk problems are address in the prototyp...    3.5      0.0   \n",
       "1  1.1  To simulate portions of the desired final prod...    5.0      1.0   \n",
       "2  1.1  A prototype program simulates the behaviors of...    4.0      1.0   \n",
       "3  1.1  Defined in the Specification phase a prototype...    5.0      1.0   \n",
       "4  1.1  It is used to let the users have a first idea ...    3.0      0.0   \n",
       "\n",
       "                                      processed_text  \n",
       "0  high risk problem address prototyp program mak...  \n",
       "1  simul portion desir final product quick easi p...  \n",
       "2  prototyp program simul behavior portion desir ...  \n",
       "3  defin specif phase prototyp stimul behavior po...  \n",
       "4  use let user first idea complet program allow ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/dbbrandt/short_answer_granding_capstone_project/master/data/sag/answers.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Initialize tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatize and Stem\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    stemmed = [stemmer.stem(word) for word in lemmatized]\n",
    "    \n",
    "    return ' '.join(stemmed)\n",
    "\n",
    "data['processed_text'] = data['answer'].apply(preprocess)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db79af58-7b73-493f-b013-b774ff7f13df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/administrator/.local/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/administrator/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/administrator/.local/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize the processed text\n",
    "tokenized_text = data['processed_text'].apply(word_tokenize)\n",
    "\n",
    "# CBOW Model\n",
    "cbow_model = Word2Vec(tokenized_text, vector_size=100, window=5, min_count=1, workers=4, sg=0)\n",
    "\n",
    "# Skip-Gram Model\n",
    "skipgram_model = Word2Vec(tokenized_text, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "# Get average Word2Vec vectors\n",
    "def get_word2vec_vector(text, model, vector_size):\n",
    "    words = text.split()\n",
    "    vector = np.mean([model.wv[word] for word in words if word in model.wv], axis=0)\n",
    "    if isinstance(vector, np.ndarray):\n",
    "        return vector\n",
    "    else:\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "vector_size = 100\n",
    "data['cbow_vector'] = data['processed_text'].apply(lambda x: get_word2vec_vector(x, cbow_model, vector_size))\n",
    "data['skipgram_vector'] = data['processed_text'].apply(lambda x: get_word2vec_vector(x, skipgram_model, vector_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c75fc04a-dd16-4c25-bd07-68ad1c43ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Bag of Words\n",
    "count_vectorizer = CountVectorizer()\n",
    "bow_vectors = count_vectorizer.fit_transform(data['processed_text']).toarray()\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(data['processed_text']).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a49d969-ddca-45e7-998b-d79e90d9f610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR - MSE: 1.7030858972420004, RMSE: 1.3050233320680518, MAE: 0.8798653207308738\n",
      "Linear Regression - MSE: 1.1781586155580486, RMSE: 1.085430152316605, MAE: 0.8412702334847901\n",
      "Decision Tree - MSE: 1.9973632002306012, RMSE: 1.4132810054021816, MAE: 1.0026801759930595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['cbow_vector'].tolist(), data['score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert lists to arrays\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Initialize models\n",
    "svr = SVR()\n",
    "lr = LinearRegression()\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "# Train models\n",
    "svr.fit(X_train, y_train)\n",
    "lr.fit(X_train, y_train)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_svr = svr.predict(X_test)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "def evaluate(y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    return mse, rmse, mae\n",
    "\n",
    "mse_svr, rmse_svr, mae_svr = evaluate(y_test, y_pred_svr)\n",
    "mse_lr, rmse_lr, mae_lr = evaluate(y_test, y_pred_lr)\n",
    "mse_dt, rmse_dt, mae_dt = evaluate(y_test, y_pred_dt)\n",
    "\n",
    "print(f'SVR - MSE: {mse_svr}, RMSE: {rmse_svr}, MAE: {mae_svr}')\n",
    "print(f'Linear Regression - MSE: {mse_lr}, RMSE: {rmse_lr}, MAE: {mae_lr}')\n",
    "print(f'Decision Tree - MSE: {mse_dt}, RMSE: {rmse_dt}, MAE: {mae_dt}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d97b76b5-d0f1-4473-9bd4-c8f9d2ca3f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is Linear Regression with RMSE: 1.085430152316605\n"
     ]
    }
   ],
   "source": [
    "best_model = min(\n",
    "    [('SVR', rmse_svr), ('Linear Regression', rmse_lr), ('Decision Tree', rmse_dt)],\n",
    "    key=lambda x: x[1]\n",
    ")\n",
    "print(f'Best model is {best_model[0]} with RMSE: {best_model[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9426d336-4f9b-4b6b-afd4-6ae5e0c986ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
