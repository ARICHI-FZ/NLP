{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T09:02:42.226336Z",
     "iopub.status.busy": "2023-11-06T09:02:42.225850Z",
     "iopub.status.idle": "2023-11-06T09:02:42.834203Z",
     "shell.execute_reply": "2023-11-06T09:02:42.832425Z",
     "shell.execute_reply.started": "2023-11-06T09:02:42.226296Z"
    }
   },
   "outputs": [],
   "source": [
    "# import required functions, classes\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import warnings\n",
    "\n",
    "# To filter out all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T09:02:49.454114Z",
     "iopub.status.busy": "2023-11-06T09:02:49.453530Z",
     "iopub.status.idle": "2023-11-06T09:03:05.488401Z",
     "shell.execute_reply": "2023-11-06T09:03:05.486812Z",
     "shell.execute_reply.started": "2023-11-06T09:02:49.454080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T09:03:11.360825Z",
     "iopub.status.busy": "2023-11-06T09:03:11.360160Z",
     "iopub.status.idle": "2023-11-06T09:03:11.495077Z",
     "shell.execute_reply": "2023-11-06T09:03:11.493708Z",
     "shell.execute_reply.started": "2023-11-06T09:03:11.360772Z"
    }
   },
   "outputs": [],
   "source": [
    "train_essays = pd.read_csv('llm-detect-ai-generated-text/train_essays.csv')\n",
    "train_prompts = pd.read_csv('llm-detect-ai-generated-text/train_prompts.csv')\n",
    "test = pd.read_csv('llm-detect-ai-generated-text/test_essays.csv')\n",
    "submission = pd.read_csv('llm-detect-ai-generated-text/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T09:03:15.268296Z",
     "iopub.status.busy": "2023-11-06T09:03:15.267740Z",
     "iopub.status.idle": "2023-11-06T09:03:15.300070Z",
     "shell.execute_reply": "2023-11-06T09:03:15.298574Z",
     "shell.execute_reply.started": "2023-11-06T09:03:15.268251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>0</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prompt_id                                               text  \\\n",
       "0  0059830c          0  Cars. Cars have been around since they became ...   \n",
       "1  005db917          0  Transportation is a large necessity in most co...   \n",
       "2  008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
       "3  00940276          0  How often do you ride in a car? Do you drive a...   \n",
       "4  00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n",
       "\n",
       "   generated  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T09:03:21.663680Z",
     "iopub.status.busy": "2023-11-06T09:03:21.661791Z",
     "iopub.status.idle": "2023-11-06T09:03:52.670557Z",
     "shell.execute_reply": "2023-11-06T09:03:52.669126Z",
     "shell.execute_reply.started": "2023-11-06T09:03:21.663621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5efea7e56798491ea056989b6dd053cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369abf20e0474c138495dc607c9a31d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86aadc52637424b88184e93c425b33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279d28c49247494c9c8e3b69a398eb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d56f209f3f544658a13a7911a8c459c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cars are a wonderful thing. They are perhaps one of the most influential inventions in modern history. They are the most important and most important thing in the world. They are the most important thing in the world because they are the most important thing in the world because they are the most important thing in the world because they are the most important thing in the world because they are the most important thing in the world because they are the most important thing in the world because they are the most important thing in the world because they are the most important thing in the world because they are the most important thing in the world because they are the most important thing in the world because they are the most important thing in the world because they are the most important thing in\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "def generate_summary(input_text):\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_length=150, num_return_sequences=1)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Example usage\n",
    "input_text = \"Cars are a wonderful thing. They are perhaps one of the most influential inventions in modern history.\"\n",
    "summary = generate_summary(input_text)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T09:03:59.414433Z",
     "iopub.status.busy": "2023-11-06T09:03:59.413223Z",
     "iopub.status.idle": "2023-11-06T09:04:08.628453Z",
     "shell.execute_reply": "2023-11-06T09:04:08.627244Z",
     "shell.execute_reply.started": "2023-11-06T09:03:59.414375Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How are you?\n",
      "AI: I'm doing well, thank you. How about you?\n",
      "AI: I'm doing well, thank you.\n",
      "AI: I'm doing well, thank you.\n",
      "AI: I'm doing well, thank you.\n",
      "AI: I'm doing well, thank you.\n",
      "AI: I'm doing well, thank you.\n",
      "AI: I'm doing well, thank you.\n",
      "AI: I'm doing well, thank you.\n",
      "AI: I'm doing well, thank you.\n",
      "AI: I'm doing well, thank you.\n",
      "AI: I'm doing well, thank you.\n",
      "AI: I'm doing well, thank you.\n",
      "AI: I'm doing well,\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "def generate_dialogue(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_length=150, num_return_sequences=1)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Example usage\n",
    "prompt = \"User: How are you?\\nAI: I'm doing well, thank you. How about you?\"\n",
    "response = generate_dialogue(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T09:04:15.505539Z",
     "iopub.status.busy": "2023-11-06T09:04:15.505094Z",
     "iopub.status.idle": "2023-11-06T09:04:24.805988Z",
     "shell.execute_reply": "2023-11-06T09:04:24.804636Z",
     "shell.execute_reply.started": "2023-11-06T09:04:15.505491Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a field of flowers, where the wind gently blows, the sun shines, and the moon shines, the sun shines.\n",
      "\n",
      "The sun shines, and the moon shines.\n",
      "\n",
      "The sun shines, and the moon shines.\n",
      "\n",
      "The sun shines, and the moon shines.\n",
      "\n",
      "The sun shines, and the moon shines.\n",
      "\n",
      "The sun shines, and the moon shines.\n",
      "\n",
      "The sun shines, and the moon shines.\n",
      "\n",
      "The sun shines, and the moon shines.\n",
      "\n",
      "The sun shines, and the moon shines.\n",
      "\n",
      "The sun shines, and the moon shines.\n",
      "\n",
      "The sun shines, and the moon shines.\n",
      "\n",
      "The sun shines, and the moon shines.\n",
      "\n",
      "The sun\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "def generate_poem(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_length=150, num_return_sequences=1)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Example usage\n",
    "prompt = \"In a field of flowers, where the wind gently blows,\"\n",
    "poem = generate_poem(prompt)\n",
    "print(poem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T09:04:29.716820Z",
     "iopub.status.busy": "2023-11-06T09:04:29.715943Z",
     "iopub.status.idle": "2023-11-06T09:04:38.647068Z",
     "shell.execute_reply": "2023-11-06T09:04:38.645762Z",
     "shell.execute_reply.started": "2023-11-06T09:04:29.716765Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def add_numbers(a, b):\n",
      "    return a + b\n",
      "\n",
      "def add_numbers(a, b):\n",
      "\n",
      "# Add a number to the list\n",
      "\n",
      "# Add a number to the list\n",
      "\n",
      "# Add a number to the list\n",
      "\n",
      "# Add a number to the list\n",
      "\n",
      "# Add a number to the list\n",
      "\n",
      "# Add a number to the list\n",
      "\n",
      "# Add a number to the list\n",
      "\n",
      "# Add a number to the list\n",
      "\n",
      "# Add a number to the list\n",
      "\n",
      "# Add a number to the list\n",
      "\n",
      "# Add a number to the list\n",
      "\n",
      "# Add a number to the list\n",
      "\n",
      "# Add a number to the list\n",
      "\n",
      "#\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "def generate_code(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_length=150, num_return_sequences=1)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Example usage\n",
    "prompt = \"def add_numbers(a, b):\\n    return a + b\"\n",
    "code = generate_code(prompt)\n",
    "print(code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T09:06:47.128140Z",
     "iopub.status.busy": "2023-11-06T09:06:47.127635Z",
     "iopub.status.idle": "2023-11-06T09:06:48.863669Z",
     "shell.execute_reply": "2023-11-06T09:06:48.861953Z",
     "shell.execute_reply.started": "2023-11-06T09:06:47.128101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9963768115942029\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       275\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           1.00       276\n",
      "   macro avg       0.50      0.50      0.50       276\n",
      "weighted avg       0.99      1.00      0.99       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming 'train_essays' is the DataFrame with 'text' and 'generated' columns\n",
    "X = train_essays['text']\n",
    "y = train_essays['generated']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a classification model (e.g., Naive Bayes)\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T09:06:54.314491Z",
     "iopub.status.busy": "2023-11-06T09:06:54.314050Z",
     "iopub.status.idle": "2023-11-06T09:07:13.830237Z",
     "shell.execute_reply": "2023-11-06T09:07:13.828995Z",
     "shell.execute_reply.started": "2023-11-06T09:06:54.314458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ceecfa7a5249a78e784a5675df219a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a48e59a4ec545dc98076fbbc70e86fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33cc44eef919404b831353a1a49ef2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b09e9d4fa9a4e04a12c19ea535b514f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'I-MISC', 'score': 0.4892812, 'index': 1, 'word': 'Cars', 'start': 0, 'end': 4}, {'entity': 'I-PER', 'score': 0.98991233, 'index': 16, 'word': 'Henry', 'start': 72, 'end': 77}, {'entity': 'I-PER', 'score': 0.87904125, 'index': 17, 'word': 'Ford', 'start': 78, 'end': 82}, {'entity': 'I-MISC', 'score': 0.95905507, 'index': 23, 'word': 'Model', 'start': 111, 'end': 116}, {'entity': 'I-MISC', 'score': 0.9839882, 'index': 24, 'word': '##T', 'start': 116, 'end': 117}, {'entity': 'I-MISC', 'score': 0.9978219, 'index': 84, 'word': 'German', 'start': 369, 'end': 375}, {'entity': 'I-MISC', 'score': 0.7542636, 'index': 85, 'word': 'Sub', 'start': 376, 'end': 379}, {'entity': 'I-MISC', 'score': 0.856638, 'index': 93, 'word': 'Cars', 'start': 405, 'end': 409}, {'entity': 'I-PER', 'score': 0.99943763, 'index': 97, 'word': 'Elizabeth', 'start': 415, 'end': 424}, {'entity': 'I-PER', 'score': 0.9997048, 'index': 98, 'word': 'Rosen', 'start': 425, 'end': 430}, {'entity': 'I-PER', 'score': 0.9988109, 'index': 99, 'word': '##thal', 'start': 430, 'end': 434}, {'entity': 'I-LOC', 'score': 0.99929225, 'index': 119, 'word': 'Shanghai', 'start': 528, 'end': 536}, {'entity': 'I-LOC', 'score': 0.9995797, 'index': 121, 'word': 'Chicago', 'start': 540, 'end': 547}, {'entity': 'I-LOC', 'score': 0.9998264, 'index': 164, 'word': 'Europe', 'start': 762, 'end': 768}, {'entity': 'I-LOC', 'score': 0.99972385, 'index': 182, 'word': 'United', 'start': 826, 'end': 832}, {'entity': 'I-LOC', 'score': 0.9996586, 'index': 183, 'word': 'States', 'start': 833, 'end': 839}, {'entity': 'I-LOC', 'score': 0.99941385, 'index': 217, 'word': 'Paris', 'start': 1000, 'end': 1005}, {'entity': 'I-PER', 'score': 0.99944776, 'index': 229, 'word': 'Robert', 'start': 1036, 'end': 1042}, {'entity': 'I-PER', 'score': 0.9997497, 'index': 230, 'word': 'Duff', 'start': 1043, 'end': 1047}, {'entity': 'I-PER', 'score': 0.99692696, 'index': 231, 'word': '##er', 'start': 1047, 'end': 1049}, {'entity': 'I-LOC', 'score': 0.99964976, 'index': 235, 'word': 'Paris', 'start': 1060, 'end': 1065}, {'entity': 'I-LOC', 'score': 0.9997029, 'index': 318, 'word': 'Paris', 'start': 1439, 'end': 1444}, {'entity': 'I-LOC', 'score': 0.99943525, 'index': 359, 'word': 'Bo', 'start': 1616, 'end': 1618}, {'entity': 'I-LOC', 'score': 0.99968517, 'index': 360, 'word': '##got', 'start': 1618, 'end': 1621}, {'entity': 'I-LOC', 'score': 0.9995066, 'index': 361, 'word': '##a', 'start': 1621, 'end': 1622}, {'entity': 'I-PER', 'score': 0.99945074, 'index': 365, 'word': 'Andrew', 'start': 1628, 'end': 1634}, {'entity': 'I-PER', 'score': 0.99976903, 'index': 366, 'word': 'Se', 'start': 1635, 'end': 1637}, {'entity': 'I-PER', 'score': 0.9376192, 'index': 367, 'word': '##ls', 'start': 1637, 'end': 1639}, {'entity': 'I-PER', 'score': 0.9895738, 'index': 368, 'word': '##ky', 'start': 1639, 'end': 1641}, {'entity': 'I-LOC', 'score': 0.9830679, 'index': 385, 'word': 'Columbia', 'start': 1714, 'end': 1722}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(task=\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "text = train_essays['text'][0]\n",
    "\n",
    "entities = ner(text)\n",
    "print(entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T09:08:24.948555Z",
     "iopub.status.busy": "2023-11-06T09:08:24.948031Z",
     "iopub.status.idle": "2023-11-06T09:08:38.834215Z",
     "shell.execute_reply": "2023-11-06T09:08:38.832304Z",
     "shell.execute_reply.started": "2023-11-06T09:08:24.948498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "cars car people driving just pollution usage world air use\n",
      "Topic 1:\n",
      "ithe ahe ito college people ao voite ii elecitoral ia\n",
      "Topic 2:\n",
      "cars car people day smog city paris pollution world driving\n",
      "Topic 3:\n",
      "car cars usage people limiting pollution air environment smog source\n",
      "Topic 4:\n",
      "electoral college vote president states people votes electors popular election\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=5000, stop_words='english')\n",
    "X = vectorizer.fit_transform(train_essays['text'])\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "# Get the most important words for each topic\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "for i, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {i}:\")\n",
    "    print(\" \".join([feature_names[j] for j in topic.argsort()[:-10 - 1:-1]]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
